<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>README</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<h1 id="whisper-ui-1.2.16">Whisper UI 1.2.16</h1>
<p>A simple GUI to transcribe audio using OpenAI’s Whisper models.</p>
<h2 id="installation">Installation</h2>
<p>Whisper-UI requires Python.</p>
<p>If you are not familiar with Python, be sure to install from <a
href="https://www.python.org/">python.org</a>. Be sure to confirm the
following:</p>
<ul>
<li>If you see a checkbox about adding Python to your PATH, be sure to
check it.</li>
<li>You should install Python version 3.11.0 or higher.</li>
<li>If you see a checkbox about installing <code>tkinter</code>,
<code>tk</code>, or <code>tcl</code>, be sure to check it.
<code>tkinter</code> is required for this program to run.</li>
</ul>
<p>After installation, it is simple to confirm that everything went
well:</p>
<ul>
<li>Open a terminal window or command prompt.</li>
<li>Enter <code>python --version</code>. If <code>python</code> is
unrecognized, then Python has not been added to your PATH (or is not
installed).</li>
<li>If the output is not “Python 3.11.0” (or some higher version like
3.11.1 or 3.12.0), your version is too low.</li>
<li>Enter <code>python -c "import tkinter"</code>. If nothing happens,
you are all set. If you see some error, <code>tkinter</code> was not
installed with your Python distribution.</li>
</ul>
<p>Whisper relies on a popular open-source audio/video converter called
<code>ffmpeg</code>. You must install this as well.</p>
<p><a
href="https://github.com/BtbN/FFmpeg-Builds/archive/refs/tags/latest.zip">ffmpeg
source code for Windows</a></p>
<p>Here is a <a
href="https://www.geeksforgeeks.org/how-to-install-ffmpeg-on-windows/">Windows
tutorial</a>, as well as <a
href="https://superuser.com/questions/624561/install-ffmpeg-on-os-x">a
good StackExchange post for Mac</a>.</p>
<h3 id="windows">Windows</h3>
<p>Download <code>Whisper UI.cmd</code> from this repository (or click
the download link for Windows). Place it wherever you like on your
computer. You can launch the program by running this file. Expect it to
take a bit of time to start up the first time you run it as it installs
itself.</p>
<h3 id="linuxmac">Linux/Mac</h3>
<p>Download <code>Whisper_UI.app</code> from this repository (or click
the download link for Linux/Mac). Place it wherever you like on your
computer. You can launch the program by running this file. Expect it to
take a bit of time to start up the first time you run it as it installs
itself.</p>
<h2 id="interface">Interface</h2>
<h3 id="menu-bar">Menu bar</h3>
<h4 id="file-menu">File menu</h4>
<ul>
<li>“Open file” - select an audio file from your computer to
transcribe.</li>
<li>“Open audio directory” - select a folder from your computer
containing audio files to transcribe. Avoid choosing a directory
containing non-audio files.</li>
<li>“Choose output directory” - select a folder from your computer to
write transcriptions to.</li>
</ul>
<h4 id="download-models">Download models</h4>
<p>A list of available models can be viewed here. A checkmark indicates
you have already downloaded the model, while a download symbol is shown
otherwise. Simply click on a model to initiate the download process.</p>
<h4 id="debug">Debug</h4>
<p>If the UI is glitching at all, try navigating here and clicking
“Reload window.”</p>
<h3 id="console">Console</h3>
<p>Most of the window is occupied by the console, which will display
information as you adjust settings and run transcription. The “clear
output” button at the bottom of the console can be used to erase all the
information on screen.</p>
<h3 id="controls">Controls</h3>
<h4 id="input-files">Input files</h4>
<p>The first text box allows you to entire a Unix-style pathname pattern
to find audio files you want to transcribe:</p>
<ul>
<li>You can enter an absolute or relative path to a file on your
computer, or select multiple files by entering an asterisk (*) somewhere
in the path. The asterisk can stand for (match) any folder or file name,
and even partial folder and filenames. For instance, if you have a
folder called <code>audio_files</code> which contains
<code>sample1.mp3</code> and <code>sample2.mp3</code>, you can grab both
of them at once by writing <code>audio_files/*.mp3</code> (or
<code>audio_files/*</code> if there are no other files in the
folder).</li>
<li>You can fill this box by typing or by going to “File” &gt; “Open
file” or “File” &gt; “Open audio directory.”</li>
<li>You can drag files onto the text box to fill it with their
paths.</li>
</ul>
<p>Once you have entered a path or paths, you can click “List files” to
display a list of all files that were found.</p>
<p>If you are ready to transcribe, you can hit “Transcribe.” Acceptable
filetypes include: <code>.flac</code>, <code>.m4a</code>,
<code>.mp3</code>, <code>.mp4</code>, and <code>.wav</code>.</p>
<h4 id="output-files">Output files</h4>
<p>The second textbox allows you to specify the folder where you want to
put the transcripts. You can enter a path to any folder. If you enter a
path to a folder that doesn’t exist, that folder will be created. You
can click “Set output directory” to confirm the existence of the chosen
folder. You can fill this box by typing or by going to “File” &gt;
“Choose output directory.”</p>
<p>The three checkboxes below the second textbox allow you to control
which kinds of output you want.</p>
<ul>
<li>Check “Output plain transcript txt?” to get a plain
<code>.txt</code> file containing the transcribed text.</li>
<li>Check “Output segmentation file?” to get a <code>.seg</code> file
showing the “segments” of your audio file (lengths of speech with breaks
between them). By default, this file is a tab-separated values, with
each line containing the speech occurring in a segment, the start time,
and the end time.</li>
<li>Check “Output full JSON output?” to get the full <code>.json</code>
output of Whisper, which also includes a detected language code if no
language is specified.</li>
</ul>
<p>“Template formatting options…” allows you to modify the format of the
plain <code>.txt</code> file and the way each line in the
<code>.seg</code> file are formatted. If you modify these, be sure to
click “Save” to save your choices.</p>
<h5 id="formatting-the-.txt-output">Formatting the <code>.txt</code>
output</h5>
<ul>
<li>“Template for full transcript” allows you to decide how to format
the transcript. By default, this field contains only the symbol
<code>&lt;&lt;&lt;TEXT&gt;&gt;&gt;</code>.</li>
<li>“Symbol to replace with full transcript” allows you to decide what
symbol in the above template is replaced with the transcript.</li>
<li>Example: If you want the transcript to be repeated a second time
with an ellipsis between, you would enter
<code>&lt;&lt;&lt;TEXT&gt;&gt;&gt;...&lt;&lt;&lt;TEXT&gt;&gt;&gt;</code>
into the “Template for full transcript” field.</li>
</ul>
<h5 id="formatting-the-.seg-output">Formatting the <code>.seg</code>
output</h5>
<ul>
<li>“Template for each segment” allows you to decide how to format the
lines of the <code>.seg</code> file. By default, this field contains the
pattern
<code>&lt;&lt;&lt;SEG&gt;&gt;&gt;\t&lt;&lt;&lt;START&gt;&gt;&gt;\t&lt;&lt;&lt;END&gt;&gt;&gt;</code>.
This formatting will write the speech segment’s text, then the start
time, and finally the end time, with <code>tab</code> characters in
between.</li>
<li>“Symbol to replace with segment in each line” allows you to decide
what symbol in the above template is replaced with a speech segment in
each line of the <code>.seg</code> file.</li>
<li>“Symbol to replace with start time in each line” works just like the
segment symbol, but is replaced by the start time of the segment.</li>
<li>“Symbol to replace with end time in each line” works just like the
segment symbol, but is replaced by the end time of the segment.</li>
</ul>
<h4 id="whisper-options">Whisper options</h4>
<p>“Currently selected Whisper model” displays the current model you are
using. Any model having the <code>.en</code> suffix is a monolingual
English model, and should not be used for other languages. All other
models are multilingual. In general, models further down the list will
be more accurate, but slower to run. They may also require more memory
than your computer has. It is quite safe to attempt to use any model you
like, but be advised that you may need to switch to a smaller one if a
larger one fails.</p>
<p>“Currently selected Whisper language” displays the language Whisper
will use to condition its output. You can set it to “NONE” if you prefer
that Whisper automatically detect the spoken language. This may also be
preferable for code-switched speech, but be advised that code-switched
data in general is fairly hard to find in order to train speech models
on it. As such, Whisper may handle code-switching rather poorly. Note
that Whisper will generally struggle with low-resource languages.</p>
<p>Check “Translate to English?” if you would like the transcript of
your non-English audio to be output in English. Note that Whisper will
generally struggle to translate from low-resource languages.</p>
<h2 id="future-updates">Future updates</h2>
<p>I plan to expand this project in the future to allow access to a
curated collection of ASR models from HuggingFace, but this will take
some time. <a
href="https://huggingface.co/spaces/hf-audio/open_asr_leaderboard">Other
models on HF under consideration include WhisperX and some NVIDIA speech
models like Canary and Parakeet.</a></p>
<p>I encourage feedback and suggestions for improvement. Please feel
free to open an issue on <a
href="https://github.com/dan-the-meme-man/whisper-ui/issues">the Issues
page</a> if you have any ideas or problems, or send me an email at <a
href="mailto:drd92@georgetown.edu">drd92@georgetown.edu</a>.</p>
</body>
</html>
